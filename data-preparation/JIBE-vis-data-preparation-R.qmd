---
title: "JIBE Melbourne Mode Choice Preparation and Analysis"
format: gfm
execute:
  # no data is to be included in this document, unless intentionally over-ridden
  output: false 
knitr:
  opts_chunk: 
    collapse: true
---

# JIBE-Vis data preparation

The JIBE-Vis project (aka VicHealth-Viz) aims to make the [Joining Impact models of transport
with spatial measures of the Built Environment (JIBE) project](https://jibeproject.com) modelling outputs accessible and useful for stakeholders, both in Melbourne and Manchester.  More broadly, the proposed platform (https://transporthealthimpacts.org) is intended to serve as an ongoing outlet for data stories illustrating the health impacts of transport planning scenarios.

This [Quarto](https://quarto.org/) markdown document will be used to record additional data processing undertaken using JIBE modelling outputs and additional external data for inclusion in the [Transport Health Impacts](https://transporthealthimpacts.org) data platform.

## Status

14 October 2024: commenced, in progress

## Background

Through the JIBE project (Joining Impact models of transport with spatial measures of the Built Environment) and the associated [AToM project](https://doi.org/10.1080/15472450.2024.2372894) ( Activity-based and agent-based Transport model of Melbourne), we have developed agent-based transport simulation models (ABMs) capable of depicting complex urban systems. These ABMs model how street-level built environment exposures influence behaviour, accessibility and health with high spatial and demographic granularity. By forecasting travel itineraries, behaviours, exposures, and health for a synthetic population of individuals, these ABMs allow us to simulate scenarios of interest to health and transport planners. However, the complexity of the models and their extensive, detailed outputs can be a barrier to effective knowledge translation and therefore impact.

This web site provides illustrative examples of potential functionality that we could implement in an interactive tool to make transport and health modelling results from JIBE and similar projects accessible and useful. Through our engagement with stakeholders, we will incorporate and test new functionality that can help meet their needs and achieve this goal. The website is being developed as open source software on [GitHub](https://github.com/jibeproject/jibe-vis).

The approach to complex systems modelling undertaken in the JIBE project is illustrated in the following diagram:
![JIBE model diagram](https://github.com/jibeproject/jibe-vis/blob/main/diagrams/jibe-model-diagram.png?raw=true)
 
### Aims
We plan to engage government and advocacy stakeholders and researchers to co-develop an interactive platform with two related aims:

1. To make complex urban systems modelling evidence accessible and useful for informing healthy transport planning policy and localised infrastructure interventions; and
2. Support visualising the impacts of modelled transportation scenarios.

We plan to publish the methods and visualisation platform developed through this work as open source code that can be adapted by other researchers and practitioners for new settings for translation of research evidence into practice.
 
## JIBE outputs

The JIBE outputs are stored in a shared sharepoint/Teams folder ([JIBE working group](https://rmiteduau.sharepoint.com/:f:/r/sites/JIBEworkinggroup/Shared%20Documents/General?csf=1&web=1&e=xxdKd0)) that contains the following sub-folders:

- documentation
  - a spreadsheet for documenting outputs and their documentation
- manchester
  - documentation and outputs relating to the Manchester modelling components:
    - accessibility
    - airPollutant
    - health
    - MATSim
    - network
    - noise
    - physicalActivity
    - skims
    - synPop
- melbourne
  - documentation and outputs relating to the Melbourne modelling components
    - 20min_interventions
    - addresses
    - cycling_intervention
    - dem
    - freight
    - gtfs
    - health
    - injuries
    - network
    - noise
    - osm
    - poi
    - regions
    - synthetic_population
- visualisation
  - documentation and outputs related to the JIBE visualisation research translation project component, including this notebook and a copy of the Transport Health Impacts website code (a NodeJS typescript website, authored using the React framework).  Because of challenges with syncing and building/rebuilding NodeJS libraries, the actual development is occurring in an offline folder.  This folder contains a copy of the code repository https://github.com/jibeproject/jibe-vis.  The app itself is deployed upon successful code pushes to GitHub using AWS Amplify, at https://transporthealthimpacts.org.
  - This notebook is now being commenced as a refinement of seperate OneNote records, and will also record future planned data preparation drawing on data located in the above mentioned folders.

## Pre-requisites
Code was authored using [R](https://cloud.r-project.org/) 4.4.1 and [Positron 2024.10.0-14](https://github.com/posit-dev/positron/releases/tag/2024.10.0-14) IDE.

No data or data-related outputs will be included in this document or repository. By default, output is set to False. For non-sensitive aspects, e.g. displaying the sessionInfo() after running analysis, this may be over-ridden.

Note that due to limitations of the Postrion IDA (currently in Beta), large code chunks must be split up in order to note exceed R's internal console buffer size.  So, this will be done below (for example, when defining area data).

The following code will help ensure all following code is run from a fresh R instance.
```{r}
rm(list = ls()) # clear memory
```

## General principles

A number of steps must be undertake for data to be included in the Transport Health Impacts (aka JIBE Vis) platform.  Data should be prepared at the appropriate scales required for visualisation with only the relevant variables that will be used.  Reducing the complexity of data in this way will result in lower file sizes and improved performance when streaming data over the internet and processing it on user's computers (which may be mobile phones, laptops or desktop computers).

In general, data which is to be mapped is required in the Protomaps [pmtiles](https://docs.protomaps.com/pmtiles/) format.  These is a vector map tile format, optimised for streaming complex data at a range of spatial scales for use in interactive map visualisations.  These files will be uploaded to the `tiles` folder in the Transport Health Impacts platform's Amazon Web Services (AWS) S3 storage bucket.

In order to get spatial data into the pmtiles format, the software [Tippecanoe](https://github.com/felt/tippecanoe) is used.  Tippecanoe can convert CSV, Geojson, or ideally Flatgeobuf data into vector map tiles in the required format.  Details on the conversion of source data into the required formats will be included in this document.  Tippecanoe should be installed in order to perform this conversion.  The above link contains [instructions](https://github.com/felt/tippecanoe?tab=readme-ov-file#installation) for installing and/or running Tippecanoe locally.  It is easiest on MacOS (`$ brew install tippecanoe`); the code below will assume a local installation has been conducted in this way.  Windows users may find it more convenient running Tippecanoe in a [Docker](https://github.com/felt/tippecanoe?tab=readme-ov-file#docker-image) container, in which case the equivalent Tippecanoe commands listed in this document may be better run directly.

Additional data processing and formatting will be undertaken as required, and documented here.

The following helper function(s) will be used later:

```{r}
spatial_data_to_fgb <- function(spatial_data, output_path, layer = NULL, filter_condition = NULL) {

  if (is.null(layer)) {
    feature_data <- st_read(spatial_data)
  }  else {
    feature_data <- st_read(spatial_data, layer = layer)
  }
  
  # Filter, if defined
  if (!is.null(filter_condition)) {
    feature_data <- feature_data %>%
      filter(!!rlang::parse_expr(filter_condition))
  }
  
  # Transform the boundary to EPSG 4326
  feature_data <- st_transform(feature_data, crs = 4326)
  
  # Extract the directory path from the output file path
  output_dir <- dirname(output_path)
  
  # Check if the directory exists, and if not, create it
  if (!dir.exists(output_dir)) {
    dir.create(output_dir, recursive = TRUE)
  }
  
  # Export the filtered boundary to a FlatGeobuf (fgb) file
  st_write(feature_data, output_path, append = FALSE)
  
  # Confirm the export
  cat("Feature data exported to", output_path, "\n")
  
  return(feature_data)
}
```

## System environment set up
Project dependencies are described in the [`renv.lock`](./renv.lock)
file; see [renv](https://rstudio.github.io/renv/) for more information.
Instructions on installing dependencies using an `renv` lock file are
[here](https://rstudio.github.io/renv/articles/renv.html#installing-packages).

With `renv` installed, dependencies were installed by running:

```
renv::install(c('arrow','conflicted','fastDummies','janitor','knitr','tidyverse','sf','dplyr'))
```

```{r}
library(arrow) # for writing Parquet files
library(conflicted) # package conflict handling https://stackoverflow.com/a/75058976
library(janitor) # data cleaning
library(knitr) # presentation
library(tidyverse) # data handling
library(fastDummies) # binary dummy variable utility
library(sf) # for spatial data handling
library(dplyr)

conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
```

## Data sources

Initialising `data` object which will contain descriptions of the data used for modelling and representing aspects each of Manchester and Melbourne.

```{r}
data <- list(Manchester = list(), Melbourne = list(), Munich = list())
```

All data used should be specified including the following aspects, separated by commas (as demonstrated below):

- source: the path to the data relative to shared project folder (JIBE Working Group)
- description: A brief plain language description of this data
- variable: A list of relevant variables present in this data (using revised names, if optionally renamed, below)
- rename: An optional list mapping old names to new names in the order: old = new
- metadata: A list detailing this dataset's provenance:
  - publisher: For example, 'Office of National Statistics (UK'
  - date_published: For example, '2023'
  - dataset: The official name for this data.
  - url: The URL from which this data may be retrieved.
  - date_accessed: For example, '11 October 2024'
  - licence: The licence governing usage of this data
  - notes: Any relevant notes on usage
- layer: The layer this data is contained with in (option, if relevant, e.g. for a layer in a geopackage)
- filter: An optional filter expression (e.g. "Name == 'Greater Manchester'")
- output: A file path for any derived outputs based on this data

### Manchester areas
```{r}
data$Manchester[["areas"]] <- list()
```

#### Output Areas (OA)

```{r}
data$Manchester$areas[["OA"]] = list(
  source="manchester/synPop/sp_2021/OA_2021_MCR.shp",
  description = "Output Areas (2021)",
  variable = list(
    OA21CD = 'Output Area 2021 code',
    LSOA21CD = 'LSOA 2021 code',
    LSOA21NM = 'LSOA 2021 name',
    id = 'Synthetic population zone linkage code for Output Areas'
  ),
  metadata = list(
    publisher = 'Office for National Statistics',
    date_published = '2023',
    dataset = 'Output Areas (December 2021) Boundaries EW BGC (V2',
    url = 'https://geoportal.statistics.gov.uk/datasets/6beafcfd9b9c4c9993a06b6b199d7e6d_0',
    date_accessed = '19 August 2024',
    notes = "This data has been modified with a seprate unique linkage code zone id by the JIBE project team for modelling purposes.",
    licence = 'Open Government Licence (UK'
  )
)


data$Manchester$areas[["OA_linkage"]] = list(
  source="visualisation/external_data/Office of National Statistics/Output_Area_to_Lower_layer_Super_Output_Area_to_Middle_layer_Super_Output_Area_to_Local_Authority_District_(December_2021)_Lookup_in_England_and_Wales_v3.csv",
  description = "Output Areas linkage codes (LSOA, MSOA, LAD) (2021)",
  variable = list(
  ),
  metadata = list(
    publisher = 'Office for National Statistics',
    date_published = '2024',
    dataset = 'Output Area (2021) to LSOA to MSOA to LAD (December 2021) Exact Fit Lookup in EW (V3) Office for National Statistics Exact Fit Lookup',
    url = 'https://geoportal.statistics.gov.uk/datasets/b9ca90c10aaa4b8d9791e9859a38ca67_0',
    date_accessed = '16 October 2024',
    licence = 'Open Government Licence (UK'
  )
)
```

#### Lower layer Super Output Areas (LSOA)
```{r}
data$Manchester$areas[["LSOA"]] = list(
  source="visualisation/external_data/Office of National Statistics/Lower_layer_Super_Output_Areas_2021_EW_BGC_V3_4023609225507911834.gpkg",
  description = "Lower layer Super Output Areas (2021)",
  variable = list(
  ),
  metadata = list(
    publisher = 'Office for National Statistics',
    date_published = '2024',
    dataset = 'Lower layer Super Output Areas (December 2021) Boundaries EW BGC (V3',
    url = 'https://geoportal.statistics.gov.uk/datasets/d082c4679075463db28bcc8ca2099ade_0',
    date_accessed = '16 October 2024',
    licence = 'Open Government Licence (UK'
  ),
  output = "visualisation/derived_data/FlatGeobufs/GreaterManchester_LSOA_ONS_2024.fgb"
)
```

#### Middle layer Super Output Areas (MSOA)
```{r}
data$Manchester$areas[["MSOA"]] = list(
  source="visualisation/external_data/Office of National Statistics/MSOA_2021_EW_BGC_V2_6515647442419654873.gpkg",
  description = "Middle layer Super Output Areas (2021)",
  variable = list(
  ),
  metadata = list(
    publisher = 'Office for National Statistics',
    date_published = '2023',
    dataset = 'Middle layer Super Output Areas (December 2021) Boundaries EW BGC (V2',
    url = 'https://geoportal.statistics.gov.uk/datasets/ed5c7b7d733d4fd582281f9bfc9f02a2_0',
    date_accessed = '16 October 2024',
    licence = 'Open Government Licence (UK'
  ),
  output = "visualisation/derived_data/FlatGeobufs/GreaterManchester_MSOA_ONS_2024.fgb"
)
```

#### Local Authority Districts (LAD)
```{r}
data$Manchester$areas[["LAD"]] = list(
  source="visualisation/external_data/Office of National Statistics/Local_Authority_Districts_December_2022_UK_BGC_V2_-4517174194749745377.gpkg",
  description = "Local Authority Districts (2022)",
  variable = list(
  ),
  metadata = list(
    publisher = 'Office for National Statistics',
    date_published = '2023',
    dataset = 'Local Authority Districts (December 2022) Boundaries UK BGC',
    url = 'https://geoportal.statistics.gov.uk/datasets/995533eee7e44848bf4e663498634849_0',
    date_accessed = '16 October 2024',
    licence = 'Open Government Licence (UK'
  ),
  output = "visualisation/derived_data/FlatGeobufs/GreaterManchester_LAD_ONS_2024.fgb"
)
```

#### Greater Manchester
Greater Manchester is a ceremonial county; documentation on cermonial counties is included in the Ordnance Survey Boundary-Line geopackage download, specified below.

```{r}
data$Manchester$areas[["GreaterManchester"]] = list(
  source="visualisation/external_data/Ordnance Survey/bdline_gpkg_gb/Data/bdline_gb.gpkg",
  description = "Greater Manchester",
  variable = list(
  ),
  metadata = list(
    publisher = 'Ordnance Survey',
    date_published = '2024',
    dataset = 'Boundary-Line™',
    url = 'https://osdatahub.os.uk/downloads/open/BoundaryLine',
    date_accessed = '11 October 2024',
    licence = 'Open Government Licence (UK',
    notes = "bdline_gpkg_gb/Data/bdline_gb.gpkg|layername=boundary_line_ceremonial_counties|subset=\"Name\" = 'Greater Manchester'"
  ),
  layer = "boundary_line_ceremonial_counties",
  filter = "Name == 'Greater Manchester'",
  output = "visualisation/derived_data/FlatGeobufs/GreaterManchester_OrdnanceSurvey_2024.fgb"
)
```


### Manchester Network

The following variables were supplied for all versions of the JIBE network to be used for visualisation (2024-10-18).  The variables car85PercSpeedKPH, bikeStressJct and walkStressJct were not recommended for us in Melbourne, due to challenges in sourcing appropriate data.
```{r}
network_variables <- list(
  edgeID = 'identifier – unique for link but same for both directions',
  name = 'road name',
  linkID = 'identifier – based on edgeID but unique in both directions',
  fwd = 'binary – forward or reverse direction',
  carSpeedLimitMPH = 'speed limit in mph',
  car85PercSpeedKPH = 'observed vehicle speeds in kph',
  aadt = 'total AADT in both directions – this is the variable used to estimate cycling stress',
  car = 'binary, whether cars allowed on link',
  bike = 'binary, whether bikes allowed on link. Always matches the walk variable, but in some cases cyclists must dismount',
  walk = 'binary, whether walking allowed on link)
  dismount (binary, whether cyclists must dismount on the link',
  gradient = 'slope in m / m',
  bikeProtectionType = 'level of cycle protection, from best to worst: KERBED (i.e., offroad), PROTECTED, LANE, MIXED)',
  VGVI = 'greenness visibility',
  freightPOIs = 'density of freight-related POIs, with 0 best and 1 worst. This can increase cycling stress by up to 20%',
  bikeStressDiscrete = 'bike stress using discrete classifications based on DfT guidance, from best to worst: GREEN, AMBER, RED',
  bikeStress = 'bike stress as a continuous variable based on above, with 0 best and 1 worst)',
  bikeStressJct = 'bike junction stress, with 0 best and 1 worst',
  walkStressJct = 'walk junction stress, with 0 best and 1 worst'
)
```


```{r}
data$Manchester[["network"]] <- list()
```

```{r}
data$Manchester$network[["reference"]] <- list(
  source="visualisation/network/net2way_manchester.gpkg",
  description = "Manchester reference network"
)
```

```{r}
data$Manchester$network[["intervention"]] <- list(
  source="visualisation/network/net2way_manchester_cycleIntervention.gpkg",
  layer="links",
  description = "Manchester network with reduced speed limits and improved cycling infrastructure"
)
```

### Manchester Synthetic population
```{r}
data$Manchester[["population"]] <- list()
```

#### Persons
```{r}
data$Manchester$population[["persons"]] <- list(
  source = "manchester/synpop/sp_2021/pp_health_2021.csv",
  description = "A generated representation of Greater Manchester's population characteristics, risks and outcomes (synthetic population).",
  citation = "?",
  variables = list(
    personid = "person id", # renamed from id
    hhid = "household id",
    age = "in years",
    gender = "male (1), female (2)",
    relationship = "role within the household",
    occupation = "toddler (0), student (3), employed (1), unemployed (2), retiree (4)",
    driversLicense = "true or false",
    workplace = "job id (0 if person is not employed)",
    income = "in £",
    disability = "Disability status (?)",
    schoolId = "N/A (unless we present flow models)",
    totalTravelTime_sec = "Travel time to…",
    totalActivityTime_min = "Moderate/vigorous physical activity (?; mins)",
    totalTimeAtHome_min = "Time spend at home (mins)",
    lightInjuryRisk = "?",
    severeInjuryRisk = "?",
    fatalityRisk = "?",
    mmetHr_walk = "marginal metabolic equivalent task hours per week (mMET-h/wk) 1 ",
    mmetHr_cycle = "mMET (h/wk)",
    exposure_pm25 = "Exclude ?",
    exposure_no2 = "Exclude ?",
    exposure_normalised_pm25 = "PM2.5 exposure (µg/m3?) 2",
    exposure_normalised_no2 = "NO2 exposure (µg/m3?) 3",
    rr_walk = "Relative risk of injury when taking a walking trip?",
    rr_cycle = "Relative risk of injury when taking a cycling trip?",
    rr_pm25 = "Relative risk of injury per cubic metre exposure to …",
    rr_no2 = "Relative risk of injury per cubic metre exposure to …",
    rr_all = "?"
  ),
  rename = list(
    'id'= 'personId'
  )
)
```

#### Households
Dwelling ID (dwelling) and Household ID (id; omitted) appear identical (assert id==dwelling)
```{r}
data$Manchester$population[["households"]] <- list(
  source = "manchester/synpop/sp_2021/hh_2021.csv",
  description = "A generated representation of Greater Manchester household characteristics, risks and outcomes (synthetic population).",
  citation = "?",
  variables = list(
    hhid = "Household id",
    zone = "Output Area",
    hhSize = "Number of persons in household",
    autos = "Number of cars in household (0, 1, 2, >3)"
  ),
  rename = list(
    'id'= 'hhid',
    'zone' = 'zone_hh'
  )
)
```

#### Dwellings
As per investigation further below, dwelling ID are household ID are identical in households dataset, but not in this data (assert id==hhID).  To link with households, hhID must be used.  Will omit dwelling coordinates from merged data.
```{r}
data$Manchester$population[["dwellings"]] <- list(
  source = "manchester/synpop/sp_2021/dd_2021.csv",
  description = "A generated representation of Manchester's population characteristics, risks and outcomes (synthetic population).",
  citation = "?",
  variables = list(
    hhid = "household id", #renamed for consistency
    zone = "Output Area",
    dw_type = "Dwelling type ((SFD: single-family detached, SFA: single-family attached, MF234: building with 2 to 4 units, MF5plus: building with 5 or more units)",
    bedrooms = "Number of bedrooms",
    quality = "Dwelling quality (1 to 4, being 1 top quality)",
    monthlyCost = "Rent (£/month)",
    yearBuilt = "Construction year",
    floor = "Floor area (m²)"
  ),
  rename = list(
    'zone' = 'zone_dw',
    'id' = 'dwid',
    'type' = 'dw_type'
  )
)
```

#### Jobs
```{r}
data$Manchester$population[["jobs"]] <- list(
  source = "manchester/synpop/sp_2021/jj_2021.csv",
  description = "A generated representation of Greater Manchester's employment characteristics, risks and outcomes (synthetic population).",
  citation = "?",
  variables = list(
    jobid = "job id",
    zone = "Output Area",
    personId = "person id",  # renamed for consistency
    job_type = "job type by industry"
  ),
  rename = list(
    'id' = 'jobid',
    'zone' = 'zone_jj',
    'type' = 'job_type'
  )
)
```


## Processing
### Manchester network

Network data in the JIBE project is produced through an iterative agent-based modelling approach according to the JIBE model above.  Broadly, a range of exposures are linked to the network and then their influence on travel behaviours evaluated in conjunction with travel population survey data evaluated using the MITO (Microscopic Transportation Orchestrator; for travel demand) and SILO (Simple Integrated Land- Use Orchestrator; for land use) frameworks and MatSIM simulation software.  As such, different network data may be generated under different scenario conditions.  This can be used to evaluate the spatial and population change in exposures and outcomes resulting from specific urban planning interventions (e.g. low traffic speed zones, and investment in cycling infrastructure).

Network data used in MatSIM may be bi-directional, and when visualising this consideration must be given to how this will be represented and structured as data.  While attributes on network segments may vary by direction, typically the geometries do not (in fact, they are duplicated).  This means that a dataset's size may be significantly reduced by only including the single set of geometries and retaining the relevant variables (potentially having inbound and outbound variants).  Where there is difference in inbound and outbound routes, or it could be anticipated, there are options for representing this: there could be a systematic offset to represent the same network geometries side by side, with colour variation based on directional attributes; or, a function could be applied (e.g. the 'worst' statistic could be displayed). Alternately, another way of reducing data size is to remove all variables except the most important (e.g. traffic stress) and an ID variable that could be used on click to retrieve other relevant data as required.

#### Read in network data
```{r}
#| output: true
network <- st_read(
  paste0('../../../',
    data$Manchester$network$intervention$source
  ), 
  layer = data$Manchester$network$intervention$layer
  )

network %>% summary()
```

Number of edges in each direction:
```{r}
network$fwd %>% table()
```

### Manchester population
```{r}
synpop <- list()
for (key in names(data$Manchester$population)) {
  synpop[[key]] <- read_csv(paste0("../../../",data$Manchester$population[[key]]$source))
}
```

#### Check population data
Household and dwelling ID are identical in the households dataset (confirmed below).  This is because only allow one household lives in the dwelling (discussed with Dr Qin Zhang, who prepared this data, on 16 October 2024).
```{r}
#| output: true
stopifnot(identical(synpop$households$id, synpop$households$dwelling))
```

However, in the dwellings dataset the dwelling and household IDs differ (confirmed below; commented out) due to presence of vacant dwellings, where household ID has been coded as -1.
```{r}
#| output: true
# stopifnot(identical(synpop$dwellings$id, synpop$dwellings$hhID))
```

Its not true for the dwellings data that dwelling id and household id variables are identical... which makes things a bit awkward, as it implies that linkage of one or the other may have an error.

Here is demonstration that household id and dwelling id are identical for households data:
```{r}
#| output: true
synpop$households[c("id","dwelling")] %>% summary()
```

Here is demonstration of how they differ within the dwellings data:
```{r}
#| output: true
synpop$dwellings[c("id","hhID")] %>% summary()
```

I confirmed with Dr Qin Zhang that matching on householed ID is the appropriate approach.

Renaming some variables to avoid ambiguity and for consistency to simplify linkage:
```{r}
for (key in names(data$Manchester$population)) {
  if ('rename' %in% names(data$Manchester$population[[key]])) {
      cat(key)
      rename_list <- setNames(
        names(data$Manchester$population[[key]]$rename),
        data$Manchester$population[[key]]$rename
      )
      # Rename the columns in synpop[[key]]
      synpop[[key]] <- synpop[[key]] %>% rename(!!!rename_list)
  }
}
```

We should now be ready to join datasets

#### Join population data
```{r}
synpop[["merged"]] <- synpop$persons %>%
   left_join(synpop$jobs, by = "personId") %>%
   left_join(synpop$households, by = "hhid") %>%
   left_join(synpop$dwellings, by = c("hhid" = "hhID"))
```

Display a summary of the merged data
```{r}
#| output: true
synpop$merged %>% summary(na.rm=False)
```

Confirm that the zone variable from households and dwellings are identical, as an extra check that this merge has worked as intended
```{r}
#| output: true
stopifnot(identical(synpop$merged$zone_hh,synpop$merged$zone_dw))
```

In the above data, I have renamed variables to ensure they are unique (e.g. 'type' for dwellings and jobs, respectively renamed to 'type_dw' and 'type_jobs'.  In this way, all the variables listed in the data dictionaries above reflect the variables post-renaming that may be exported in the joined dataset.

#### How to use the population data?

I am thinking, because there are so many records (approximately 3 million) it will be inefficient to attach to store all these variables with geometries for querying.  Better might be, have the LSOA geometries with zone id that can then be used to retrieve and query the relevant subset of persons on click and display summary statistics.  Could maybe use parquet on S3, queried with Amazon Athena...  apparently that's quite cheap and fast for this kind of task.

But... these persons etc are not linked to LSOAs, they are linked to Output Areas.  So --- in fact, what we want to do is get the relevant other area linkage variables all attached to people... 

Retrieved OA look up tables for LSOA, MSOA and LAD (regions).  Need to 

- Link up the merged data with the MCR output area data using the derived 'zone' id and get the 2021 OA and LSOA codes.  
- Join with the look up table to get MSOA and LAD codes.  
- Then retrieve 2021 LSOA, MSOA and LAD geometries,
  - restrict them to linkage codes present in the data
  - export as geojson or if possible, FlatGeoBuf files for use with [Tippecanoe](https://github.com/felt/tippecanoe)
  - create pmtiles using Tippecanoe, and upload to S3 bucket

Should consider whether its worth pre-processing summaries in the area data, or better to just retrieve on demand... But first things first.

#### Link up merged data with OA and LSOA codes for further linkage

```{r}
#| output: true
oa_geoms <- st_read(paste0("../../../",data$Manchester$areas$OA$source))

# Select the relevant attributes, omitting the geometries
shp_attributes <- oa_geoms %>%
  st_set_geometry(NULL) %>%
  select(id, OA21CD, LSOA21CD)  # Replace with actual attribute names

# Perform a left join to merge the attributes with your existing data frame
# And rename variables ending in .x as home, and .y as job
# "OA21CD.x"                 "LSOA21CD.x"            
# "OA21CD.y"                 "LSOA21CD.y"        
synpop$merged <- (synpop$merged %>%
  left_join(shp_attributes, by = c("zone_hh" = "id")) %>%
  left_join(shp_attributes, by = c("zone_jj" = "id")))%>%
  rename("OA21CD.home" = "OA21CD.x") %>%
  rename("LSOA21CD.home" = "LSOA21CD.x") %>%
  rename("OA21CD.job" = "OA21CD.y") %>%
  rename("LSOA21CD.job" = "LSOA21CD.y")
synpop$merged %>% names()
```

### Manchester areas
#### Which boundaries to use?

When retrieving boundaries from the UK Office of National Statistics, these are offered at a range of resolutions:

> - Full Extent (BFE) – Full resolution boundaries go to the Extent of the Realm (Low Water Mark) and are the most detailed of the boundaries.
> - Full Clipped (BFC) – Full resolution boundaries that are clipped to the coastline (Mean High Water mark).
> - Generalised Clipped (BGC) - Generalised to 20m and clipped to the coastline (Mean High Water mark) and more generalised than the BFE boundaries.
> - Super Generalised Clipped (BSC) (200m) – Generalised to 200m and clipped to the coastline (Mean High Water mark).
> - Ultra Generalised Clipped (BUC) (500m) – Generalised to 500m and clipped to the coastline (Mean High Water mark).
> - Grid, Extent (BGE) - Grid formed of equally sized cells which extend beyond the coastline.
> - Generalised, Grid (BGG) - Generalised 50m grid squares.

(copied from https://geoportal.statistics.gov.uk/)

We do not require full resolution boundaries; generalised clipped boundaries (to 20m; BGC) will be sufficient for purposes of providing contextual information for Manchester regions.

While we could retrieve and use the OA boundaries, and we will retain the OA code in case we want to later, for now we will just get LSOA, MSOA and LAD (local area districts).  Even then, maybe for now, I will just use MSOA and LAD for proof of concept.  Then we can trial representing them with minimal data as a boundary overlay of JIBE attributes; when an area is clicked on, population data will be queried and an interactive graphical distirbution summary for that area provided.  Perhaps, as a reference, we could produce one set of summary statistics for Manchester as a whole, so the selected area can be compared against the region (eg min, 25th, 50th, 75th percentiles and max, as well as mean and standard deviation).

#### Read in OA look up tables for MSOA and LAD codes

```{r}
#| output: true
oa_lookup <- read_csv(paste0('../../../',data$Manchester$areas$OA_linkage$source))
oa_lookup_selected <- oa_lookup %>%
  select(OA21CD, MSOA21CD, LAD22CD)

synpop$merged <- synpop$merged %>%
  left_join(oa_lookup_selected, by = c("OA21CD.home"="OA21CD")) %>%
  left_join(oa_lookup_selected, by = c("OA21CD.job"="OA21CD")) %>%
  rename("MSOA21CD.home" = "MSOA21CD.x") %>%
  rename("LAD22CD.home" = "LAD22CD.x") %>%
  rename("MSOA21CD.job" = "MSOA21CD.y") %>%
  rename("LAD22CD.job" = "LAD22CD.y")
synpop$merged %>% names()
```

#### Write population with linkage codes to Parquet

```{r}
#| output: true
parquet_output_path <- "../../../visualisation/derived_data/parquet/synpop_manchester_2021.parquet"
output_dir <- dirname(parquet_output_path)
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}
write_parquet(synpop$merged, parquet_output_path)
cat("Merged synthetic population data written to Parquet file at", parquet_output_path, "\n")
```

#### Convert Manchester areas to FlatGeobuf data

```{r}
#| output: true

area <- data$Manchester$areas$GreaterManchester

# Check if the output is specified and ends with .fgb
if (!is.null(area$output) && grepl("\\.fgb$", area$output)) {
  # Define the geopackage path and output path
  in_path <- paste0('../../../', area$source)
  out_path <- paste0('../../../', area$output)
  if ('layer' %in% names(area)) {
    layer <- area$layer
  } else {
    layer <- NULL
  }
  if ('filter' %in% names(area)) {
    filter <- area$filter
  } else {
    filter <- NULL
  }
  
  # Apply the spatial_data_to_fgb function
  data$Manchester$areas$GreaterManchester[['data']] <- spatial_data_to_fgb(in_path, out_path, layer, filter)
}

```


The LSOA data is actually really quite detailed with many features; we may not even depict this except perhaps for home/work trajectory representation.  It will be better restricting LSOA, MSOA and LAD to those referenced in the synpop$merged dataset, so we'll run that output again manually restricting only to those areas having recorded home or job locations. 

```{r}
#| output: true
# Define the area types to loop over
area_types <- c('LSOA', 'MSOA','LAD')
area_id_lookup <- list(
  LSOA = 'LSOA21CD',
  MSOA = 'MSOA21CD',
  LAD = 'LAD22CD'
)
# Loop over each area type
for (area_type in area_types) {
  area_id <- area_id_lookup[area_type]
  # Create a unique list of values for homes and jobs based on the area type
  filter_values <- unique(c(synpop$merged[[paste0(area_id,'.home')]], synpop$merged[[paste0(area_id,'.job')]]))
  
  # Format these values as a character vector within the filter string
  filter_string <- paste0(
    area_id,
    " %in% c('", 
    paste(filter_values, collapse = "','"),
    "')"
  )
  print(filter_string)
 
  # Apply the spatial_data_to_fgb function with the correct filter string
  spatial_data_to_fgb(
    paste0('../../../', data$Manchester$areas[[area_type]]$source),
    paste0('../../../', data$Manchester$areas[[area_type]]$output),
    filter_condition = filter_string
  )
}
```

#### Generate pmtiles file containing Manchester area layers

```{r}
#| output: true

output_pmtiles <- "../../../visualisation/derived_data/PMTiles/Manchester.pmtiles"
output_dir <- dirname(output_pmtiles)

# Check if the directory exists, and if not, create it
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}
areas <- c()
# Get the list of output fgb files
for (area_name in names(data$Manchester$areas)) {
  area <- data$Manchester$areas[[area_name]]
  # Check if the output is specified and ends with .fgb
  if (!is.null(area$output) && is.character(area$output)) {
    areas <- areas %>% append(paste0('../../../', area$output))
  }
}
tippecanoe_command <- paste(
    "tippecanoe",
    "-o", 
    output_pmtiles,
    "-zg",
    paste(areas, collapse=" ")
)

# Print the command to verify
cat("Running command:", tippecanoe_command)

# Run the tippecanoe command
system(tippecanoe_command)

```

### Generate Manchester 


## Generating Basemaps

Basemaps for the Transport Health Impacts platform are generated and visualised based on OpenStreetMap data using the Protomaps [PMTiles](https://github.com/protomaps/PMTiles) specification and tools.

At time of writing, basemaps for selected areas can be generated locally (as described below), or downloaded using an interactive map from https://app.protomaps.com/.

To generate a baseman for relevant region locally
1. Get and install PMTiles

  - see directions at https://github.com/protomaps/PMTiles
  - for MacOSX with Home Brew: `brew install pmtiles` (as per https://formulae.brew.sh/formula/pmtiles)

2. Run command, e.g.

  - `pmtiles extract  https://build.protomaps.com/20240812.pmtiles manchester_2024-08-12.pmtiles --bbox=-3.2907,52.9202,-1.1804,54.0346`
	- `pmtiles extract  https://build.protomaps.com/20240812.pmtiles munich_2024-08-12.pmtiles --bbox=11.0439,47.8297,12.0714,48.4927`
	- `pmtiles extract https://build.protomaps.com/20240812.pmtiles victoria_2024-08-12.pmtiles --bbox=139.55,-39.42,150.46,-33.75`

3. Merge basemaps, optionally:

`tile-join -o jibe_basemap.pmtiles manchester_2024-08-12.pmtiles munich_2024-08-12.pmtiles victoria_2024-08-12.pmtiles`


Credit Protomaps and OpenStreetMap Contributors under ODbL, e.g.
[Protomaps](https://protomaps.com/) © [OpenStreetMap](https://openstreetmap.org/)